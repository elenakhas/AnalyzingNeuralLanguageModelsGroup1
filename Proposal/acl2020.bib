\bibliography{anthology,acl2020}
\bibliographystyle{acl_natbib}



@article{Belinkov_2019,
author = {Belinkov, Yonatan and Glass, James},
title = {Analysis Methods in Neural Language Processing: A Survey},
journal = {Transactions of the Association for Computational Linguistics},
volume = {7},
number = {},
pages = {49-72},
year = {2019},
doi = {10.1162/tacl\_a\_00254},

URL = { 
        https://doi.org/10.1162/tacl_a_00254
    
},
eprint = { 
        https://doi.org/10.1162/tacl_a_00254
    
}
,
    abstract = { The field of natural language processing has seen impressive progress in recent years, with neural network models replacing many of the traditional systems. A plethora of new models have been proposed, many of which are thought to be opaque compared to their feature-rich counterparts. This has led researchers to analyze, interpret, and evaluate neural networks in novel and more fine-grained ways. In this survey paper, we review analysis methods in neural language processing, categorize them according to prominent research trends, highlight existing limitations, and point to potential directions for future work. }
}


@inproceedings{bizzoni-lappin-2018-predicting,
    title = "Predicting Human Metaphor Paraphrase Judgments with Deep Neural Networks",
    author = {Bizzoni, Yuri  and
      Lappin, Shalom},
    booktitle = "Proceedings of the Workshop on Figurative Language Processing",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-0906",
    doi = "10.18653/v1/W18-0906",
    pages = "45--55",
    abstract = "We propose a new annotated corpus for metaphor interpretation by paraphrase, and a novel DNN model for performing this task. Our corpus consists of 200 sets of 5 sentences, with each set containing one reference metaphorical sentence, and four ranked candidate paraphrases. Our model is trained for a binary classification of paraphrase candidates, and then used to predict graded paraphrase acceptability. It reaches an encouraging 75{\%} accuracy on the binary classification task, and high Pearson (.75) and Spearman (.68) correlations on the gradient judgment prediction task.",
}

@misc{shwartz2019pain,
    title={Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition},
    author={Vered Shwartz and Ido Dagan},
    year={2019},
    eprint={1902.10618},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{van_Aken_2019,
   title={How Does BERT Answer Questions?},
   ISBN={9781450369763},
   url={http://dx.doi.org/10.1145/3357384.3358028},
   DOI={10.1145/3357384.3358028},
   journal={Proceedings of the 28th ACM International Conference on Information and Knowledge Management  - CIKM  ’19},
   publisher={ACM Press},
   author={van Aken, Betty and Winter, Benjamin and Löser, Alexander and Gers, Felix A.},
   year={2019}
}


@article{Wang_2019,
   title={Evaluating word embedding models: methods and experimental results},
   volume={8},
   ISSN={2048-7703},
   url={http://dx.doi.org/10.1017/ATSIP.2019.12},
   DOI={10.1017/atsip.2019.12},
   journal={APSIPA Transactions on Signal and Information Processing},
   publisher={Cambridge University Press (CUP)},
   author={Wang, Bin and Wang, Angela and Chen, Fenxiao and Wang, Yuncheng and Kuo, C.-C. Jay},
   year={2019}
}


@article{wang_wang_chen_wang_kuo_2019, title={Evaluating word embedding models: methods and experimental results}, volume={8}, DOI={10.1017/ATSIP.2019.12}, journal={APSIPA Transactions on Signal and Information Processing}, publisher={Cambridge University Press}, author={Wang, Bin and Wang, Angela and Chen, Fenxiao and Wang, Yuncheng and Kuo, C.-C. Jay}, year={2019}, pages={e19}}





@misc{zhou2019evaluating,
    title={Evaluating Commonsense in Pre-trained Language Models},
    author={Zhou, Xuhui and Zhang, Yue and Cui, Leyang and Huang, Dandan },
    year={2019},
    eprint={1911.11931},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{huang_cho_bowman_2020, title={Can we identify word senses from deep contextualized word embeddings without supervision?}, url={https://medium.com/@leslie_huang/automatic-extraction-of-word-senses-from-deep-contextualized-word-embeddings-2f09f16e820}, journal={Medium}, author={Huang, Leslie and Cho, Kyunghyun and Bowman, Sam}, year={2020}, month={Jan}}

@inproceedings{faruqui-etal-2016-problems,
    title = "Problems With Evaluation of Word Embeddings Using Word Similarity Tasks",
    author = "Faruqui, Manaal  and
      Tsvetkov, Yulia  and
      Rastogi, Pushpendre  and
      Dyer, Chris",
    booktitle = "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for {NLP}",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W16-2506",
    doi = "10.18653/v1/W16-2506",
    pages = "30--35",
}

@misc{ethayarajh2019contextual,
    title={How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings},
    author={Kawin Ethayarajh},
    year={2019},
    eprint={1909.00512},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{wolf2019huggingfaces,
    title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
    author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Jamie Brew},
    year={2019},
    eprint={1910.03771},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{mccoy2019right,
    title={Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},
    author={R. Thomas McCoy and Ellie Pavlick and Tal Linzen},
    year={2019},
    eprint={1902.01007},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{niven2019probing,
    title={Probing Neural Network Comprehension of Natural Language Arguments},
    author={Timothy Niven and Hung-Yu Kao},
    year={2019},
    eprint={1907.07355},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}