{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from probe.load_data import WordInspectionDataset, SentenceParaphraseInspectionDataset\n",
    "from scipy.spatial.distance import cosine\n",
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setence_paraphrase_comparisons(tokenizer, feature_extraction_model, batch_size):\n",
    "    pdata = SentenceParaphraseInspectionDataset('paraphrase_pair_vec_sim_test.txt', tokenizer)\n",
    "    dataset = pdata.get_data()\n",
    "    embedding_outputs, encoded_inputs, indices = pdata.bert_word_embeddings(feature_extraction_model,\n",
    "                                                                            pdata.get_encoded(), batch_size)\n",
    "    sentence_embeddings = pdata.aggregate_sentence_embeddings(embedding_outputs, encoded_inputs, indices,\n",
    "                                                              aggregation_metric=torch.mean)\n",
    "\n",
    "    paraphrase_pairs = get_paraphrase_pairs(dataset)\n",
    "    paraphrase_cosine_metrics = [calculate_paraphrase_pair_similarity(pair_sents, tokenizer, dataset, embedding_outputs, encoded_inputs, sentence_embeddings) \n",
    "                            for pair_id, pair_sents in paraphrase_pairs.items()]\n",
    "    \n",
    "    return paraphrase_cosine_metrics\n",
    "\n",
    "def word_similarity_comparisons(tokenizer, feature_extraction_model, batch_size):\n",
    "    pdata = WordInspectionDataset('word_vec_sim_test.txt', tokenizer)\n",
    "    dataset = pdata.get_data()\n",
    "    embedding_outputs, encoded_inputs, _indices = pdata.bert_word_embeddings(feature_extraction_model,\n",
    "                                                                            pdata.get_encoded(), batch_size)\n",
    "    idiom_sentence_indexes = get_idiom_sentences(dataset)\n",
    "    word_cosine_metrics = [calculate_word_similarity_metrics(idiom_sent_idx, tokenizer, dataset, embedding_outputs, encoded_inputs) \n",
    "                            for idiom_sent_idx in idiom_sentence_indexes]\n",
    "    return word_cosine_metrics\n",
    "\n",
    "def get_paraphrase_pairs(dataset):\n",
    "    paraphrase_pairs = defaultdict(list)\n",
    "    for i, sent in enumerate(dataset):\n",
    "        paraphrase_pairs[sent.pair_id].append((i, sent))\n",
    "    return paraphrase_pairs\n",
    "\n",
    "def calculate_paraphrase_pair_similarity(pair, tokenizer, dataset, embedding_outputs, encoded_inputs, sentence_embeddings):\n",
    "    sent_1 = pair[0]\n",
    "    sent_2 = pair[1]\n",
    "    sent_1_index = sent_1[0]\n",
    "    sent_2_index = sent_2[0]\n",
    "    cosine_sim = 1 - cosine(sentence_embeddings[sent_1_index], sentence_embeddings[sent_2_index])\n",
    "    \n",
    "    return {\n",
    "        'pair_id': sent_1[1].pair_id,\n",
    "        'sent_1': tokenizer.decode(encoded_inputs[sent_1_index].tolist()),\n",
    "        'sent_2': tokenizer.decode(encoded_inputs[sent_2_index].tolist()),\n",
    "        'paraphrase': dataset[sent_1_index].paraphrase,\n",
    "        'judgment': dataset[sent_1_index].classifier_judgment,\n",
    "        'cosine_similarity': cosine_sim\n",
    "    }    \n",
    "\n",
    "def calculate_word_similarity_metrics(idiom_sent_index, tokenizer, dataset, embedding_outputs, encoded_inputs):\n",
    "    idiom_ex = dataset[idiom_sent_index]\n",
    "    idiom_word_embedding = get_word_embedding(tokenizer, dataset, embedding_outputs, encoded_inputs, idiom_sent_index)\n",
    "    cosine_similarity_metrics = {}\n",
    "\n",
    "    literal_usage_sents = [i for i, ex in enumerate(dataset) if ex.pair_id == idiom_ex.pair_id and \n",
    "                                                            ex.word == idiom_ex.word and not \n",
    "                                                            ex.sentence_id == idiom_ex.sentence_id ]\n",
    "    paraphrase_sents = [i for i, ex in enumerate(dataset) if ex.pair_id == idiom_ex.pair_id \n",
    "                                                            and not ex.word == idiom_ex.word]\n",
    "\n",
    "    literal_usage_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, encoded_inputs, lit_idx) for lit_idx in literal_usage_sents]\n",
    "    paraphrase_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, encoded_inputs, para_idx) for para_idx in paraphrase_sents]\n",
    "\n",
    "    cosine_similarity_metrics['fig_to_literal'] = calculate_cosine_similarity_average([idiom_word_embedding], literal_usage_embeddings)\n",
    "    cosine_similarity_metrics['literal_to_literal'] = calculate_cosine_similarity_average(literal_usage_embeddings)\n",
    "    cosine_similarity_metrics['fig_to_paraphrase'] = calculate_cosine_similarity_average([idiom_word_embedding], paraphrase_embeddings)\n",
    "    cosine_similarity_metrics['literal_to_paraphrase'] = calculate_cosine_similarity_average(literal_usage_embeddings, paraphrase_embeddings)\n",
    "    \n",
    "    return {\n",
    "        'sentence_id': idiom_ex.sentence_id,\n",
    "        'sentence': tokenizer.decode(encoded_inputs[idiom_sent_index].tolist()),\n",
    "        'word': idiom_ex.word,\n",
    "        'paraphrase_word': dataset[paraphrase_sents[0]].word,\n",
    "        'cosine_similarities': cosine_similarity_metrics,\n",
    "    }\n",
    "\n",
    "def get_idiom_sentences(dataset):\n",
    "    return [i for i, ex in enumerate(dataset) if ex.figurative]\n",
    "\n",
    "def get_sentences_for_idiom_sentence(dataset, idiom_sent):\n",
    "    literal_usage_sents = [i for i, ex in enumerate(dataset) if ex.pair_id == idiom_sent.pair_id and \n",
    "                                                                ex.word == idiom_sent.word and not \n",
    "                                                                ex.sentence_id == idiom_sent.sentence_id ]\n",
    "    paraphrase_sents = [i for i, ex in enumerate(dataset) if ex.pair_id == idiom_sent.pair_id and not \n",
    "                                                            ex.word == idiom_sent.word]\n",
    "    return (literal_usage_sents, paraphrase_sents)\n",
    "\n",
    "def get_word_embedding(tokenizer, dataset, embedding_outputs, encoded_inputs, dataset_index):\n",
    "    ex = dataset[dataset_index]\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(encoded_inputs[dataset_index].tolist())\n",
    "    word_index = decoded_tokens.index(ex.word[0])\n",
    "    return embedding_outputs[dataset_index][word_index]\n",
    "\n",
    "def calculate_cosine_similarity_average(embeddings_1, embeddings_2=None):\n",
    "    if embeddings_2:\n",
    "        embedding_pairs = list(itertools.product(embeddings_1, embeddings_2))\n",
    "    else:\n",
    "        embedding_pairs = list(itertools.combinations(embeddings_1, 2))\n",
    "\n",
    "    cosine_similarities = [1 - cosine(embedding_1, embedding_2) for embedding_1, embedding_2 in embedding_pairs]\n",
    "    return mean(cosine_similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\", do_lower_case=True)\n",
    "feature_extraction_model = BertModel.from_pretrained('bert-large-uncased')\n",
    "batch_size = 20  # totally arbitrarily chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbdf79f4a7442f29da6826233f56394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Feature extraction', max=1, style=ProgressSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 20/60 sentences, current max sentence length 17\n",
      "processed 40/60 sentences, current max sentence length 21\n",
      "processed 60/60 sentences, current max sentence length 22\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sentence_id': 1,\n",
       "  'sentence': '[CLS] the cat is out of the bag. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'word': ['cat'],\n",
       "  'paraphrase_word': ['secret'],\n",
       "  'cosine_similarities': {'fig_to_literal': 0.8095400002267625,\n",
       "   'literal_to_literal': 0.881085894174046,\n",
       "   'fig_to_paraphrase': 0.5299287855625152,\n",
       "   'literal_to_paraphrase': 0.5367808659871419}},\n",
       " {'sentence_id': 21,\n",
       "  'sentence': \"[CLS] soon we're going to hit the sack. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
       "  'word': ['sack'],\n",
       "  'paraphrase_word': ['bed'],\n",
       "  'cosine_similarities': {'fig_to_literal': 0.5062072972456614,\n",
       "   'literal_to_literal': 0.7760081390539805,\n",
       "   'fig_to_paraphrase': 0.44221730828285216,\n",
       "   'literal_to_paraphrase': 0.4630802833371692}},\n",
       " {'sentence_id': 41,\n",
       "  'sentence': '[CLS] it is time to bite the bullet. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'word': ['bullet'],\n",
       "  'paraphrase_word': ['situation'],\n",
       "  'cosine_similarities': {'fig_to_literal': 0.665409591462877,\n",
       "   'literal_to_literal': 0.8150315499967999,\n",
       "   'fig_to_paraphrase': 0.46983158588409424,\n",
       "   'literal_to_paraphrase': 0.4762022028366725}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sim_results = word_similarity_comparisons(tokenizer, feature_extraction_model, batch_size)\n",
    "\n",
    "word_sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_word_similarity_comp(results):\n",
    "    literal_sim_advantage = [result['cosine_similarities']['literal_to_literal'] - result['cosine_similarities']['fig_to_literal'] for result in results]\n",
    "    fig_to_paraphrase_advantage = [result['cosine_similarities']['fig_to_paraphrase'] - result['cosine_similarities']['literal_to_paraphrase'] for result in results]\n",
    "    \n",
    "    summary_stats = {\n",
    "        'lit_to_lit_cosine_improvement_over_fig_to_lit': mean(literal_sim_advantage),\n",
    "        'fig_to_paraphrase_cosine_improvement_over_lit_to_paraphrase': mean(fig_to_paraphrase_advantage)\n",
    "    }\n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lit_to_lit_cosine_improvement_over_fig_to_lit:  0.16365623142984184\n",
      "fig_to_paraphrase_cosine_improvement_over_lit_to_paraphrase:  -0.011361890810507333\n"
     ]
    }
   ],
   "source": [
    "word_cosine_summary_stats = summarize_word_similarity_comp(word_sim_results)\n",
    "\n",
    "for label, stat in word_cosine_summary_stats.items():\n",
    "    print(label + \": \", stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b43aa91ccaf45b5a2d124f1575ae836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Feature extraction', max=1, style=ProgressSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10/10 sentences, current max sentence length 14\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pair_id': 1,\n",
       "  'sent_1': '[CLS] the cat is out of the bag. [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'sent_2': '[CLS] it is no longer a secret. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 1,\n",
       "  'cosine_similarity': 0.796942412853241},\n",
       " {'pair_id': 2,\n",
       "  'sent_1': \"[CLS] soon we're going to hit the sack. [SEP] [PAD] [PAD]\",\n",
       "  'sent_2': \"[CLS] we'll go to bed before long. [SEP] [PAD] [PAD] [PAD]\",\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 1,\n",
       "  'cosine_similarity': 0.780309796333313},\n",
       " {'pair_id': 3,\n",
       "  'sent_1': '[CLS] it is time to bite the bullet. [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'sent_2': '[CLS] the situation, though unpleasant, must be addressed. [SEP] [PAD] [PAD]',\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 0,\n",
       "  'cosine_similarity': 0.6908389925956726},\n",
       " {'pair_id': 4,\n",
       "  'sent_1': '[CLS] she will be there at the drop of a hat. [SEP] [PAD]',\n",
       "  'sent_2': \"[CLS] instantly she'll be there. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 0,\n",
       "  'cosine_similarity': 0.9006535410881042},\n",
       " {'pair_id': 5,\n",
       "  'sent_1': '[CLS] you happen to be barking up the wrong tree. [SEP] [PAD] [PAD]',\n",
       "  'sent_2': \"[CLS] you're not correct in your current course of action. [SEP]\",\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 0,\n",
       "  'cosine_similarity': 0.8082679510116577}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_sim_results = setence_paraphrase_comparisons(tokenizer, feature_extraction_model, batch_size)\n",
    "\n",
    "sentence_sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_sentence_similarity_comp(results):\n",
    "    correctly_judged_paraphrases = [result['cosine_similarity'] for result in results if result['paraphrase'] and result['judgment']]\n",
    "    correctly_judged_non_paraphrases = [result['cosine_similarity'] for result in results if not result['paraphrase'] and not result['judgment']]\n",
    "    incorrectly_judged_paraphrases =  [result['cosine_similarity'] for result in results if result['paraphrase'] and not result['judgment']]\n",
    "    incorrectly_judged_non_paraphrases =  [result['cosine_similarity'] for result in results if not result['paraphrase'] and result['judgment']]\n",
    "\n",
    "    return {\n",
    "        'average_cosine_sim_for_correctly_judged_paraphrases': handle_zero_case(correctly_judged_paraphrases),\n",
    "        'average_cosine_sim_for_correctly_judged_non_paraphrases': handle_zero_case(correctly_judged_non_paraphrases),\n",
    "        'average_cosine_sim_for_incorrectly_judged_paraphrases': handle_zero_case(incorrectly_judged_paraphrases),\n",
    "        'average_cosine_sim_for_incorrectly_judged_non_paraphrases': handle_zero_case(incorrectly_judged_non_paraphrases)\n",
    "    }\n",
    "\n",
    "def handle_zero_case(category_results):\n",
    "    if not category_results:\n",
    "        return 'N/A'\n",
    "    return mean(category_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_cosine_sim_for_correctly_judged_paraphrases': 0.788626104593277,\n",
       " 'average_cosine_sim_for_correctly_judged_non_paraphrases': 'N/A',\n",
       " 'average_cosine_sim_for_incorrectly_judged_paraphrases': 0.7999201615651449,\n",
       " 'average_cosine_sim_for_incorrectly_judged_non_paraphrases': 'N/A'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_sentence_similarity_comp(sentence_sim_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
