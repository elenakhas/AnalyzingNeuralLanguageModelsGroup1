{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from probe.load_data import WordInspectionDataset, SentenceParaphraseInspectionDataset\n",
    "from scipy.spatial.distance import cosine\n",
    "from statistics import mean \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_paraphrase_comparisons(tokenizer, feature_extraction_model, batch_size):\n",
    "    pdata = SentenceParaphraseInspectionDataset('paraphrase_pair_vec_sim_test.txt', tokenizer)\n",
    "    dataset = pdata.get_data()\n",
    "    embedding_outputs, encoded_inputs, indices = pdata.bert_word_embeddings(\n",
    "                                                             feature_extraction_model, \n",
    "                                                             pdata.get_encoded(), batch_size)\n",
    "    sentence_embeddings = pdata.aggregate_sentence_embeddings(embedding_outputs,\n",
    "                                                              encoded_inputs, indices, \n",
    "                                                              aggregation_metric=torch.mean)\n",
    "\n",
    "    paraphrase_pairs = get_paraphrase_pairs(dataset)\n",
    "    paraphrase_cosine_metrics = [calculate_paraphrase_pair_similarity(pair_sents, tokenizer, dataset, \n",
    "                                                                      embedding_outputs, encoded_inputs, \n",
    "                                                                      sentence_embeddings) \n",
    "                                for pair_id, pair_sents in paraphrase_pairs.items()]\n",
    "    \n",
    "    return paraphrase_cosine_metrics\n",
    "\n",
    "def word_similarity_comparisons(tokenizer, feature_extraction_model, batch_size):\n",
    "    pdata = WordInspectionDataset('word_vec_sim_test.txt', tokenizer)\n",
    "    dataset = pdata.get_data()\n",
    "    embedding_outputs, encoded_inputs, _indices = pdata.bert_word_embeddings(\n",
    "                                                            feature_extraction_model,\n",
    "                                                            pdata.get_encoded(), batch_size)\n",
    "    idiom_sentence_indexes = get_idiom_sentences(dataset)\n",
    "    word_cosine_metrics = [calculate_word_similarity_metrics(idiom_sent_idx, tokenizer, dataset, \n",
    "                                                             embedding_outputs, encoded_inputs) \n",
    "                           for idiom_sent_idx in idiom_sentence_indexes]\n",
    "    return word_cosine_metrics\n",
    "\n",
    "def get_paraphrase_pairs(dataset):\n",
    "    paraphrase_pairs = defaultdict(list)\n",
    "    for i, sent in enumerate(dataset):\n",
    "        paraphrase_pairs[sent.pair_id].append((i, sent))\n",
    "    return paraphrase_pairs\n",
    "\n",
    "def calculate_paraphrase_pair_similarity(pair, tokenizer, dataset, embedding_outputs, encoded_inputs, sentence_embeddings):\n",
    "    sent_1 = pair[0]\n",
    "    sent_2 = pair[1]\n",
    "    sent_1_index = sent_1[0]\n",
    "    sent_2_index = sent_2[0]\n",
    "    cosine_sim = 1 - cosine(sentence_embeddings[sent_1_index], sentence_embeddings[sent_2_index])\n",
    "    \n",
    "    return {\n",
    "        'pair_id': sent_1[1].pair_id,\n",
    "        'sent_1': tokenizer.decode(encoded_inputs[sent_1_index].tolist()),\n",
    "        'sent_2': tokenizer.decode(encoded_inputs[sent_2_index].tolist()),\n",
    "        'paraphrase': dataset[sent_1_index].paraphrase,\n",
    "        'judgment': dataset[sent_1_index].classifier_judgment,\n",
    "        'cosine_similarity': cosine_sim\n",
    "    }    \n",
    "\n",
    "def calculate_word_similarity_metrics(idiom_sent_index, tokenizer, dataset, embedding_outputs, encoded_inputs):\n",
    "    idiom_ex = dataset[idiom_sent_index]\n",
    "    idiom_word_embedding = get_word_embedding(tokenizer, dataset, embedding_outputs, encoded_inputs, idiom_sent_index)\n",
    "    cosine_sim_metrics = {}\n",
    "\n",
    "    literal_usage_sents = [i for i, ex in enumerate(dataset) if ex.pair_id == idiom_ex.pair_id and \n",
    "                                                            ex.word == idiom_ex.word and not \n",
    "                                                            ex.sentence_id == idiom_ex.sentence_id ]\n",
    "    paraphrase_sents = [i for i, ex in enumerate(dataset) if ex.pair_id == idiom_ex.pair_id \n",
    "                                                            and not ex.word == idiom_ex.word]\n",
    "\n",
    "    literal_usage_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                   encoded_inputs, lit_idx) \n",
    "                                for lit_idx in literal_usage_sents]\n",
    "    paraphrase_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                encoded_inputs, para_idx) \n",
    "                             for para_idx in paraphrase_sents]\n",
    "\n",
    "    cosine_sim_metrics['fig_to_literal'] = calc_cosine_sim_average([idiom_word_embedding], \n",
    "                                                                          literal_usage_embeddings)\n",
    "    cosine_sim_metrics['literal_to_literal'] = calc_cosine_sim_average(literal_usage_embeddings)\n",
    "    cosine_sim_metrics['fig_to_paraphrase'] = calc_cosine_sim_average([idiom_word_embedding], \n",
    "                                                                             paraphrase_embeddings)\n",
    "    cosine_sim_metrics['literal_to_paraphrase'] = calc_cosine_sim_average(literal_usage_embeddings, \n",
    "                                                                                 paraphrase_embeddings)\n",
    "    \n",
    "    return {\n",
    "        'sentence_id': idiom_ex.sentence_id,\n",
    "        'sentence': tokenizer.decode(encoded_inputs[idiom_sent_index].tolist()),\n",
    "        'word': idiom_ex.word,\n",
    "        'paraphrase_word': dataset[paraphrase_sents[0]].word,\n",
    "        'cosine_similarities': cosine_sim_metrics,\n",
    "    }\n",
    "\n",
    "def get_idiom_sentences(dataset):\n",
    "    return [i for i, ex in enumerate(dataset) if ex.figurative]\n",
    "\n",
    "def get_sentences_for_idiom_sentence(dataset, idiom_sent):\n",
    "    literal_usage_sents = [i for i, ex in enumerate(dataset) \n",
    "                           if ex.pair_id == idiom_sent.pair_id \n",
    "                           and ex.word == idiom_sent.word\n",
    "                           and not ex.sentence_id == idiom_sent.sentence_id ]\n",
    "    paraphrase_sents = [i for i, ex in enumerate(dataset) \n",
    "                        if ex.pair_id == idiom_sent.pair_id \n",
    "                        and not ex.word == idiom_sent.word]\n",
    "    return (literal_usage_sents, paraphrase_sents)\n",
    "\n",
    "def get_word_embedding(tokenizer, dataset, embedding_outputs, encoded_inputs, dataset_index):\n",
    "    ex = dataset[dataset_index]\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(encoded_inputs[dataset_index].tolist())\n",
    "    word_index = decoded_tokens.index(ex.word[0])\n",
    "    return embedding_outputs[dataset_index][word_index]\n",
    "\n",
    "def calc_cosine_sim_average(embeddings_1, embeddings_2=None):\n",
    "    if embeddings_2:\n",
    "        embedding_pairs = list(itertools.product(embeddings_1, embeddings_2))\n",
    "    else:\n",
    "        embedding_pairs = list(itertools.combinations(embeddings_1, 2))\n",
    "\n",
    "    cosine_similarities = [1 - cosine(embedding_1, embedding_2) \n",
    "                           for embedding_1, embedding_2 in embedding_pairs]\n",
    "    return mean(cosine_similarities)\n",
    "\n",
    "def summarize_word_similarity_comp(results):\n",
    "    literal_sim_advantage = [result['cosine_similarities']['literal_to_literal'] - \n",
    "                             result['cosine_similarities']['fig_to_literal'] \n",
    "                             for result in results]\n",
    "    fig_to_paraphrase_advantage = [result['cosine_similarities']['fig_to_paraphrase'] - \n",
    "                                   result['cosine_similarities']['literal_to_paraphrase'] \n",
    "                                   for result in results]\n",
    "    \n",
    "    summary_stats = {\n",
    "        'lit_to_lit_cosine_improvement_over_fig_to_lit': mean(literal_sim_advantage),\n",
    "        'fig_to_paraphrase_cosine_improvement_over_lit_to_paraphrase': mean(fig_to_paraphrase_advantage)\n",
    "    }\n",
    "    return summary_stats\n",
    "\n",
    "def summarize_sentence_similarity_comp(results):\n",
    "    correct_paraphrases = [result['cosine_similarity'] for result in results \n",
    "                                    if result['paraphrase'] and result['judgment']]\n",
    "    correct_non_paraphrases = [result['cosine_similarity'] for result in results \n",
    "                                        if not result['paraphrase'] and not result['judgment']]\n",
    "    incorrect_paraphrases =  [result['cosine_similarity'] for result in results \n",
    "                                       if result['paraphrase'] and not result['judgment']]\n",
    "    incorrect_non_paraphrases =  [result['cosine_similarity'] for result in results \n",
    "                                           if not result['paraphrase'] and result['judgment']]\n",
    "\n",
    "    return {\n",
    "        'cosine_sim_for_correctly_judged_paraphrases': handle_empty(correct_paraphrases),\n",
    "        'cosine_sim_for_correctly_judged_non_paraphrases': handle_empty(correct_non_paraphrases),\n",
    "        'cosine_sim_for_incorrectly_judged_paraphrases': handle_empty(incorrect_paraphrases),\n",
    "        'cosine_sim_for_incorrectly_judged_non_paraphrases': handle_empty(incorrect_non_paraphrases)\n",
    "    }\n",
    "\n",
    "def handle_empty(category_results):\n",
    "    if not category_results:\n",
    "        return 'N/A'\n",
    "    return mean(category_results)\n",
    "\n",
    "def word_PCA_fig_and_lit_comparisons(dataset, embedding_outputs, encoded_inputs):\n",
    "    idiom_sentence_indexes = get_idiom_sentences(dataset)\n",
    "    \n",
    "    for idiom_sent_index in idiom_sentence_indexes:\n",
    "        idiom_ex = dataset[idiom_sent_index]\n",
    "        idiom_word_embedding = get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                  encoded_inputs, idiom_sent_index)\n",
    "        cosine_similarity_metrics = {}\n",
    "\n",
    "        literal_usage_sents = [i for i, ex in enumerate(dataset) \n",
    "                               if ex.pair_id == idiom_ex.pair_id \n",
    "                               and ex.word == idiom_ex.word \n",
    "                               and not ex.sentence_id == idiom_ex.sentence_id ]\n",
    "        paraphrase_sents = [i for i, ex in enumerate(dataset) \n",
    "                            if ex.pair_id == idiom_ex.pair_id\n",
    "                            and not ex.word == idiom_ex.word]\n",
    "\n",
    "        literal_usage_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                       encoded_inputs, lit_idx) \n",
    "                                    for lit_idx in literal_usage_sents]\n",
    "        paraphrase_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                    encoded_inputs, para_idx) \n",
    "                                 for para_idx in paraphrase_sents]\n",
    "\n",
    "        embeddings = literal_usage_embeddings + [idiom_word_embedding]\n",
    "        labels =  np.array(len(literal_usage_embeddings) * [1] + [0])\n",
    "        \n",
    "        show_fig_and_lit_PCS(embeddings, labels, idiom_ex.word[0], idiom_ex.sentence)\n",
    "\n",
    "def show_fig_and_lit_PCS(embeddings, labels, word, sentence):\n",
    "    X = torch.stack(embeddings)\n",
    "    pca = PCA(2)  \n",
    "    projected = pca.fit_transform(X)\n",
    "    target_names = ['figurative', 'literal']\n",
    "\n",
    "    for color, i, target_name in zip(['turquoise', 'navy'], [0, 1], target_names):\n",
    "        plt.scatter(projected[labels == i, 0], projected[labels == i, 1], color=color,  lw=2,\n",
    "                    label=target_name)\n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title('PCA for {}: Fig usage {}'.format(word, \" \".join(sentence)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def word_PCA_paraphrase_comparisons(dataset, embedding_outputs, encoded_inputs):\n",
    "    idiom_sentence_indexes = get_idiom_sentences(dataset)\n",
    "    \n",
    "    for idiom_sent_index in idiom_sentence_indexes:\n",
    "        idiom_ex = dataset[idiom_sent_index]\n",
    "        idiom_word_embedding = get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                  encoded_inputs, idiom_sent_index)\n",
    "        cosine_similarity_metrics = {}\n",
    "\n",
    "        literal_usage_sents = [i for i, ex in enumerate(dataset) \n",
    "                               if ex.pair_id == idiom_ex.pair_id \n",
    "                               and ex.word == idiom_ex.word \n",
    "                               and not ex.sentence_id == idiom_ex.sentence_id ]\n",
    "        paraphrase_sents = [i for i, ex in enumerate(dataset) \n",
    "                            if ex.pair_id == idiom_ex.pair_id\n",
    "                            and not ex.word == idiom_ex.word]\n",
    "\n",
    "        literal_usage_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                       encoded_inputs, lit_idx) \n",
    "                                    for lit_idx in literal_usage_sents]\n",
    "        paraphrase_embeddings = [get_word_embedding(tokenizer, dataset, embedding_outputs, \n",
    "                                                    encoded_inputs, para_idx) \n",
    "                                 for para_idx in paraphrase_sents]\n",
    "\n",
    "        embeddings = literal_usage_embeddings + [idiom_word_embedding] + paraphrase_embeddings\n",
    "        labels = np.array(len(literal_usage_embeddings)*[1] +[0]+ len(paraphrase_embeddings)*[2])\n",
    "        \n",
    "        show_PCS(embeddings, labels, idiom_ex.word[0], idiom_ex.sentence, \n",
    "                 dataset[paraphrase_sents[0]].word)\n",
    "\n",
    "def show_PCS(embeddings, labels, word, sentence, paraphrase):\n",
    "    X = torch.stack(embeddings)\n",
    "    pca = PCA(2)  \n",
    "    projected = pca.fit_transform(X)\n",
    "    target_names = ['figurative', 'literal', 'paraphrase']\n",
    "    colors = ['turquoise', 'navy', 'orangered']\n",
    "\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "        plt.scatter(projected[labels == i, 0], projected[labels == i, 1], color=color,  lw=2,\n",
    "                    label=target_name)\n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title('PCA for \"{}\" (Fig usage: \"{}\") Paraphrase word: {}'.format(word, \" \".join(sentence), paraphrase))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\", do_lower_case=True)\n",
    "feature_extraction_model = BertModel.from_pretrained('bert-large-uncased')\n",
    "batch_size = 20  # totally arbitrarily chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e5c98539914e7abbf96e36be906b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Feature extraction', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 20/60 sentences, current max sentence length 22\n",
      "processed 40/60 sentences, current max sentence length 22\n",
      "processed 60/60 sentences, current max sentence length 22\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sentence_id': 1,\n",
       "  'sentence': '[CLS] the cat is out of the bag. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'word': ['cat'],\n",
       "  'paraphrase_word': ['secret'],\n",
       "  'cosine_similarities': {'fig_to_literal': 0.8095400002267625,\n",
       "   'literal_to_literal': 0.881085894174046,\n",
       "   'fig_to_paraphrase': 0.5299287855625152,\n",
       "   'literal_to_paraphrase': 0.5367808659871419}},\n",
       " {'sentence_id': 21,\n",
       "  'sentence': \"[CLS] soon we're going to hit the sack. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
       "  'word': ['sack'],\n",
       "  'paraphrase_word': ['bed'],\n",
       "  'cosine_similarities': {'fig_to_literal': 0.5062072972456614,\n",
       "   'literal_to_literal': 0.7760081390539805,\n",
       "   'fig_to_paraphrase': 0.4422173142433167,\n",
       "   'literal_to_paraphrase': 0.4630802823437585}},\n",
       " {'sentence_id': 41,\n",
       "  'sentence': '[CLS] it is time to bite the bullet. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'word': ['bullet'],\n",
       "  'paraphrase_word': ['situation'],\n",
       "  'cosine_similarities': {'fig_to_literal': 0.665409591462877,\n",
       "   'literal_to_literal': 0.8150315499967999,\n",
       "   'fig_to_paraphrase': 0.46983158588409424,\n",
       "   'literal_to_paraphrase': 0.4762022028366725}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sim_results = word_similarity_comparisons(tokenizer, feature_extraction_model, batch_size)\n",
    "\n",
    "word_sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lit_to_lit_cosine_improvement_over_fig_to_lit:  0.16365623142984184\n",
      "fig_to_paraphrase_cosine_improvement_over_lit_to_paraphrase:  -0.011361888492548914\n"
     ]
    }
   ],
   "source": [
    "word_cosine_summary_stats = summarize_word_similarity_comp(word_sim_results)\n",
    "\n",
    "for label, stat in word_cosine_summary_stats.items():\n",
    "    print(label + \": \", stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2daffb0a2bab4745915155dc880c1df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Feature extraction', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10/10 sentences, current max sentence length 14\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pair_id': 1,\n",
       "  'sent_1': '[CLS] the cat is out of the bag. [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'sent_2': '[CLS] it is no longer a secret. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 1,\n",
       "  'cosine_similarity': 0.796942412853241},\n",
       " {'pair_id': 2,\n",
       "  'sent_1': \"[CLS] soon we're going to hit the sack. [SEP] [PAD] [PAD]\",\n",
       "  'sent_2': \"[CLS] we'll go to bed before long. [SEP] [PAD] [PAD] [PAD]\",\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 1,\n",
       "  'cosine_similarity': 0.780309796333313},\n",
       " {'pair_id': 3,\n",
       "  'sent_1': '[CLS] it is time to bite the bullet. [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       "  'sent_2': '[CLS] the situation, though unpleasant, must be addressed. [SEP] [PAD] [PAD]',\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 0,\n",
       "  'cosine_similarity': 0.6908389925956726},\n",
       " {'pair_id': 4,\n",
       "  'sent_1': '[CLS] she will be there at the drop of a hat. [SEP] [PAD]',\n",
       "  'sent_2': \"[CLS] instantly she'll be there. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\",\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 0,\n",
       "  'cosine_similarity': 0.9006535410881042},\n",
       " {'pair_id': 5,\n",
       "  'sent_1': '[CLS] you happen to be barking up the wrong tree. [SEP] [PAD] [PAD]',\n",
       "  'sent_2': \"[CLS] you're not correct in your current course of action. [SEP]\",\n",
       "  'paraphrase': 1,\n",
       "  'judgment': 0,\n",
       "  'cosine_similarity': 0.8082679510116577}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_sim_results = sentence_paraphrase_comparisons(tokenizer, feature_extraction_model, batch_size)\n",
    "\n",
    "sentence_sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cosine_sim_for_correctly_judged_paraphrases': 0.788626104593277,\n",
       " 'cosine_sim_for_correctly_judged_non_paraphrases': 'N/A',\n",
       " 'cosine_sim_for_incorrectly_judged_paraphrases': 0.7999201615651449,\n",
       " 'cosine_sim_for_incorrectly_judged_non_paraphrases': 'N/A'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_sentence_similarity_comp(sentence_sim_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9136f12841414b12b24635accbb9076c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Feature extraction', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 20/60 sentences, current max sentence length 22\n"
     ]
    }
   ],
   "source": [
    "pdata = WordInspectionDataset('word_vec_sim_test.txt', tokenizer)\n",
    "dataset = pdata.get_data()\n",
    "embedding_outputs, encoded_inputs, _indices = pdata.bert_word_embeddings(feature_extraction_model,\n",
    "                                                                    pdata.get_encoded(), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_PCA_fig_and_lit_comparisons(dataset, embedding_outputs, encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_PCA_paraphrase_comparisons(dataset, embedding_outputs, encoded_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
